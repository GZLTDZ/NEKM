{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we consider the PDE system $\\mathcal{L} \\mathbf{u} = \\mathbf{f}$ with zero Dirichlet boundary condition, where\n",
    "$$\n",
    "\\mathcal{L}=\\left[\\begin{array}{cc}\n",
    "1 & -\\lambda \\Delta \\\\\n",
    "\\lambda \\Delta & 1\n",
    "\\end{array}\\right],\n",
    "\\quad\n",
    "\\mathbf{u}=\\left[\\begin{array}{c} u_1 \\\\ u_2 \\end{array}\\right]\n",
    "\\quad\n",
    "\\mathbf{f}=\\left[\\begin{array}{c} f_1 \\\\ f_2 \\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_info = torch.cuda.get_device_properties(0)\n",
    "    print(f\"GPU: {gpu_info.name}\")\n",
    "    print(f\"GPU memory: {gpu_info.total_memory / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 41\n",
    "n = N - 1\n",
    "h = 1 / n \n",
    "m = n - 1\n",
    "m2 = m * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData1(lambda_):\n",
    "    id_m = np.identity(m)\n",
    "    d1= np.identity(m)\n",
    "    d1[0][1] = 1\n",
    "    d1[m - 1][m - 2] = 1\n",
    "    for i in range(0, m):\n",
    "        d1[i][i] = -2\n",
    "        if (i >= 1) and (i <= m - 2):\n",
    "            d1[i][i - 1] = 1\n",
    "            d1[i][i + 1] = 1\n",
    "    D = np.kron(id_m, d1) + np.kron(d1, id_m)\n",
    "    D = D / (h ** 2)\n",
    "\n",
    "    L = np.zeros((2 * m2, 2 * m2))\n",
    "    L[0: m2, 0: m2] = np.identity(m2)\n",
    "    L[0: m2, m2: 2 * m2] = - lambda_ * D\n",
    "    L[m2: 2 * m2, 0: m2] = lambda_ * D\n",
    "    L[m2: 2 * m2, m2: 2 * m2] = np.identity(m2)\n",
    "\n",
    "    L_sparse = sparse.csr_matrix(L)\n",
    "\n",
    "    f = np.random.rand(5000, 2 * m2)\n",
    "    u = np.zeros_like(f)\n",
    "    for i in range(5000):\n",
    "        u[i, :] = spsolve(L_sparse, f[i, :])\n",
    "\n",
    "    lambda_np = lambda_ + np.zeros_like(f[:, 0].reshape((-1, 1)))\n",
    "\n",
    "    return lambda_np, f, u\n",
    "\n",
    "def generateData2(lambda_values):\n",
    "    lambda_list = []\n",
    "    f_list = []\n",
    "    u_list = []\n",
    "\n",
    "    for lambda_ in lambda_values:\n",
    "        lambda_np, f, u = generateData1(lambda_)\n",
    "        lambda_list.append(lambda_np)\n",
    "        f_list.append(f)\n",
    "        u_list.append(u)\n",
    "    \n",
    "    return np.concatenate(lambda_list, axis=0), np.concatenate(f_list, axis=0), np.concatenate(u_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda__ = np.linspace(0.05, 0.1, 11)\n",
    "lambda_values, f, u = generateData2(lambda__)\n",
    "lambda_values, f, u = torch.tensor(lambda_values, dtype=torch.float32), torch.tensor(f, dtype=torch.float32), torch.tensor(u, dtype=torch.float32)\n",
    "lambda_values.shape, f.shape, u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GreenFun(nn.Module):\n",
    "    def __init__(self, N):     \n",
    "        super(GreenFun, self).__init__()\n",
    "        self.N = N\n",
    "        self.lambda_layer = nn.Sequential(nn.Linear(1, N // 4), nn.ReLU(), nn.Linear(N // 4, N // 4), nn.ReLU(), nn.Linear(N // 4, N // 4), nn.ReLU(), nn.Linear(N // 4, N // 4), nn.ReLU(), nn.Linear(N // 4, N // 4))\n",
    "        self.G_layer1 = nn.Sequential(nn.Linear(N, N // 4, bias = False))\n",
    "        self.G_layer2 = nn.Sequential(nn.Linear(N // 4, N, bias = False))\n",
    "\n",
    "    def forward(self, lambda_values,  f):   \n",
    "        return self.G_layer2(self.lambda_layer(lambda_values) * self.G_layer1(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "dataset = TensorDataset(lambda_values, f, u)\n",
    "\n",
    "# 定义训练集和测试集的大小\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# 将数据集按比例分成训练集和测试集\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 获取训练集的数据\n",
    "train_lambda = torch.stack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
    "train_f = torch.stack([train_dataset[i][1] for i in range(len(train_dataset))])\n",
    "train_u = torch.stack([train_dataset[i][2] for i in range(len(train_dataset))])\n",
    "\n",
    "# 获取测试集的数据\n",
    "test_lambda = torch.stack([test_dataset[i][0] for i in range(len(test_dataset))])\n",
    "test_f = torch.stack([test_dataset[i][1] for i in range(len(test_dataset))])\n",
    "test_u = torch.stack([test_dataset[i][2] for i in range(len(test_dataset))])\n",
    "\n",
    "train_lambda = train_lambda.to(device)\n",
    "train_f = train_f.to(device)\n",
    "train_u = train_u.to(device)\n",
    "test_lambda = test_lambda.to(device)\n",
    "test_f = test_f.to(device)\n",
    "test_u = test_u.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience, verbose, delta, path):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss > self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.best_loss:.8f} --> {val_loss:.8f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GreenFun(2 * m2).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 4500, factor=0.7)\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 60000, verbose=False, delta=1e-8, path='net.pth')\n",
    "num_epochs = 200000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = net(train_lambda, train_f)\n",
    "    \n",
    "    loss = criterion(output, train_u)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_test = net(test_lambda, test_f)\n",
    "        loss_test = criterion(output_test, test_u)\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {loss.item():.8f} Testing Loss: {loss_test.item():.8f} || lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    # 调整学习率\n",
    "    scheduler.step(loss_test)\n",
    "\n",
    "    early_stopping(loss_test, net)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"net.pth\", map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, N)\n",
    "y = np.linspace(0, 1, N)\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeErrors(u_exact, u_pre, printOrNot):\n",
    "    error = u_exact - u_pre\n",
    "    l2_norm_abs = np.linalg.norm(error, ord=2) / np.sqrt(error.size)\n",
    "    max_norm_abs = np.max(np.abs(error))\n",
    "    l2_norm_rel = np.linalg.norm(error, ord=2) / np.linalg.norm(u_exact, ord=2)\n",
    "    max_norm_rel = np.max(np.abs(error)) / np.max(np.abs(u_exact))  \n",
    "    \n",
    "    l2_norm_rel_percent = l2_norm_rel * 100\n",
    "    max_norm_rel_percent = max_norm_rel * 100\n",
    "    \n",
    "    if printOrNot == True:\n",
    "        print(f\"Absolute L2 Norm Error: {l2_norm_abs:.8f}\")\n",
    "        print(f\"Absolute Max Norm Error: {max_norm_abs:.8f}\")\n",
    "        print(f\"Relative L2 Norm Error: {l2_norm_rel_percent:.6f}%\")\n",
    "        print(f\"Relative Max Norm Error: {max_norm_rel_percent:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(lambda_, net):\n",
    "    u1_exact = np.sin(np.pi * X) * Y * (1 - Y)\n",
    "    u2_exact = X * (1 - X) * np.sin(np.pi * Y)\n",
    "    laplace_u1 = -2 * np.sin(np.pi * X) - np.pi ** 2 * u1_exact\n",
    "    laplace_u2 = -2 * np.sin(np.pi * Y) - np.pi ** 2 * u2_exact\n",
    "    f1 = u1_exact - lambda_ * laplace_u2\n",
    "    f2 = lambda_ * laplace_u1 + u2_exact\n",
    "\n",
    "    f = np.concatenate([f1[1:-1, 1:-1].flatten(), f2[1:-1, 1:-1].flatten()])\n",
    "\n",
    "    lambda_torch = (lambda_ + torch.zeros(1, 1)).to(device)\n",
    "    f_torch = torch.tensor(f, dtype=torch.float32).view(1, -1).to(device)\n",
    "\n",
    "    u_numerical_torch = net(lambda_torch, f_torch)\n",
    "    u_numerical = u_numerical_torch.cpu().detach().numpy().flatten()\n",
    "\n",
    "    u1_numerical = np.zeros_like(u1_exact)\n",
    "    u2_numerical = np.zeros_like(u2_exact)\n",
    "    u1_numerical[1:-1, 1:-1] = u_numerical[0: m2].reshape((m, m))\n",
    "    u2_numerical[1:-1, 1:-1] = u_numerical[m2: 2 * m2].reshape((m, m))\n",
    "\n",
    "    print(\"numerical result for u_1:\")\n",
    "    computeErrors(u1_exact, u1_numerical, True)\n",
    "\n",
    "    print(\"numerical result for u_2:\")\n",
    "    computeErrors(u2_exact, u2_numerical, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(0.1, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(1/15, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(0.05, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
